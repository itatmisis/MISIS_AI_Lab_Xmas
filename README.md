# X-MAS Hack 2022. Решение команды MISIS_AI_Lab для кейса 1

В данном репозитории находится решение команды MISIS_AI_Lab.
Решение представляет собой веб-портал, который позволяет может быть использован для удобной работы с различными договорами.
Вы можете получить интерпретацию договора, а также определить его класс (аренда, поставка, подряд и т.д.).

## Содержание

- [X-MAS Hack 2022. Решение команды MISIS\_AI\_Lab для кейса 1](#x-mas-hack-2022-решение-команды-misis_ai_lab-для-кейса-1)
  - [Содержание](#содержание)
  - [Описание решения](#описание-решения)
  - [Инструкция по запуску](#инструкция-по-запуску)
    - [Работа с сервисом](#работа-с-сервисом)
    - [Локальный запуск](#локальный-запуск)
    - [Структура проекта](#структура-проекта)
  - [Архитектура](#архитектура)
    - [Паттерны](#паттерны)
    - [Референсная Архитектура](#референсная-архитектура)
  - [Машинное Обучение](#машинное-обучение)
    - [Стек](#стек)
    - [Подходы](#подходы)
    - [Модели](#модели)
  - [Контакты](#контакты)

## Описание решения

Нашим решением является веб портал с наиболее актуальной информацией. На нем можно осуществить следующие действия:

- загрузить договор в различных форматах (pdf, docx, txt)
- извлечь из файла текст договора
- получить отчет по договору, в котором будет указана его классификация и интерпретация

Также, вы можете минимальную версию нашего сервиса, работающую через API.

## Инструкция по запуску

### Работа с сервисом

Фронтенд нашего сервиса доступен по ссылке:  [62.84.127.116:3001](http://62.84.127.116:3001)
Вы можете использовать его для тестирования. Однако, если вы хотите запустить сервис локально, то вам необходимо выполнить следующие действия:

### Локальный запуск

Перед тем, как развернуть у себя сервис необходимо установить [Docker](https://docs.docker.com/get-docker/) и [Docker Compose](https://docs.docker.com/compose/install) на вашу машину.

Далее, необходимо выполнить следующие действия:

```bash
# Клонируем репозиторий
git clone -b main https://github.com/itatmisis/MISIS_AI_Lab_Xmas.git
# Переходим в папку с проектом
cd MISIS_AI_Lab_Xmas/dockerItems
# Запускаем сервис
docker-compose up -d
```

Теперь вы можете открыть в браузере [localhost](http://localhost:80) и увидеть работающий сервис.  
Также, вы можете использовать следующие адреса для доступа к сервису:

- **0.0.0.0:80** - адрес фронтенда
- **0.0.0.0:8001** - статический контент для фронтенда
- **0.0.0.0:8080** - адрес backend-сервиса
- **0.0.0.0:5432** - адрес базы данных PostgreSQL
- **0.0.0.0:15672** - адрес админ-панели RabbitMQ
- **0.0.0.0:5672** - адрес брокера сообщений RabbitMQ

### Структура проекта

Репозиторий состоит из следующих папок:

- [**dockerItems**](/dockerItems/) - содержит файлы для запуска сервиса через Docker
- [**frontend**](/Front/) - содержит фронтенд нашего сервиса
- [**nginx**](/nginx/) - содержит статический контент для фронтенда
- [**Crud.API**](/Back/Crud.API/) - содержит обработчики запросов к базе данных
- [**ML_Worker**](/Back/ML_Worker/) - содержит обработчики запросов к моделям машинного обучения
- [**Xmas.API**](/Back/XmasHack.API/) - содержит обработчики запросов к брокеру сообщений

## Архитектура

На диаграмме ниже можно посмотреть на верхнеуровневую архитектуру нашего сервиса.
![АРХИТЕКТУРА.png](/readme-assets/notation.jpg)

Мы используем микросервисную архитектуру, которая позволяет нам масштабировать наш сервис по мере необходимости.
В рамках работы над прототипом были учтены лучшие практики построения подобных решений, используемые в современных проектах и разработаны собственные решения, которые позволяют нам решить поставленные задачи.  
В качестве архитектурных принципов для разных частей продукта мы опирались на следующие паттерны:

### Паттерны

- [API Gateway](https://microservices.io/patterns/apigateway.html). Он позволяет собрать все сервисы в одно целое и предоставить единый интерфейс для взаимодействия с ними.
- [Microservice architecture](https://microservices.io/patterns/microservices.html). Каждый сервис может быть развернут отдельно, а большинство коммуникаций - через REST API запросы.
- [Database per service](https://microservices.io/patterns/data/database-per-service.html). Поскольку база данных используется в нескокльких местах, мы приняли решение выделить отдельный микросервис для обспечения Create, Read, Update, Delete (CRUD) запросов
- [Event Sourcing](https://microservices.io/patterns/data/event-sourcing.html). Паттерн позволяет хранить историю изменений в базе данных. В нашем случае, это позволяет хранить историю изменений в базе данных, а также восстанавливать состояние базы данных на любой момент времени.
- [Pub-Sub](https://learn.microsoft.com/en-us/azure/architecture/patterns/publisher-subscriber). Паттерн позволяет обеспечить обмен сообщениями между микросервисами в публикацион-подписчик модели. В нашем случае, это неоюходимо для управления запросаими пользователей на обработку больших файлов.

В этой связи мы опираемся на референсные архитектуры ведущих ИТ компаний, а также используем общеприщнанные паттерны, проверенные временем.

### Референсная Архитектура

Мы старались сделать нашу архитектуру максимально простой и понятной. В этой связи мы опираемся на референсные архитектуры ведущих ИТ компаний, а также используем общеприщнанные паттерны, проверенные временем. Они позволяют нам решить следующие задачи:

- **обеспечить минимальное время ожидания для пользователя**
- **отделить бизнес логику веб сервиса от ресурсоемких задач Машинного Обучения**
- **обеспечить масштабируемость сервиса**
- **обеспечить возможность быстрого внедрения новых алгоритмов Машинного Обучения**

В качестве референсных архитектур мы взяли подход IBM в построении решений [AI for IT Operations (AIOps)](https://www.ibm.com/cloud/architecture/architectures/sm-aiops/reference-architecture), из которого мы поняли, что разбиение процесса на этапы (Collect, Organize, Analyze, Infuse) соответствуют нашим потребноостям.

## Машинное Обучение

### Стек

- **Torch** - библиотека для реализации нейронных сетей
- **xztrainer** - библиотека с обучающим пайплайном для торча
- **HuggingFace Transformers & Tokenizers & Hub** - набор библиотек от HuggingFace, используем оттуда реализацию RoBERTa
- **Tika** - библиотека для извлечения текста из документов различных форматов
- **Tesseract** - встроен в Tika, инструмент для распознавания текста из фото (OCR)
- **Razdel** - библиотека для алгоритмического разделения текста на блоки
- **Catboost** - библиотека для работы с GBDT-моделями
- **Scikit-Learn** - библиотека с алгоритмами классического МО
  
### Подходы

- **Deep Learning** - подход, основанный на нейронных сетях
- **Transfer Learning** - подход, основанный на использовании предобученных моделей
- **NLP** - подход, основанный на обработке естественного языка
- **Text Classification** - подход, основанный на классификации текста
- **Text Preprocessing** - подход, основанный на предобработке текста

### Модели

Делили выборку на main и holdout подвыборки.
Для проверки, что все работает, использовали Stratified 5-Fold на main'е. Смотрели avg и std Macro F1 score по фолдам.
Все модели были обучены на серверных мощностях с GPU.
#### CatBoost + Tf-Idf
Используются для вычленения самых важных слов/словосочетаний из документа. Достаем их по ShapValues.
Ансамблировали модели по 5 фолдам, дополнительно проверяли, что все ок, на holdout.
#### RoBERTa
После обучения на фолдах для проверки устойчивости, переобучали модель на всем main, и проверяли, что все ок, на holdout.
Обучение - сэмплировали случайные подотрезки токенов из документов.
Валидация - разделяли документ на фрагменты при помощи razdel, скорили каждый фрагмент Бертом.
Усредняли скоры по фрагментам для итогового предикта.
Показываем самые большие по вероятности фразы для каждого из классов на фронте.


## Контакты

В случае возникновения каких-либо ошибок или вопросов не стесняйтесь создавать Issue в репозитории. Также можете писать в личные сообщения @misisailab (Telegram, VK) или на почту misisailab@misis.ru
  
